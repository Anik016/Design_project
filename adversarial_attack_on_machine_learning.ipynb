{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8f6519",
   "metadata": {},
   "source": [
    "VGG-19 IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9b6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37abda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from google.colab import drive\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48822874",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224  # 224x224 as mentioned in paper\n",
    "NUM_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd077b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'E://data'\n",
    "train_path = os.path.join(dataset_path, 'train')\n",
    "test_path = os.path.join(dataset_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_path = os.path.join(train_path, 'benign')\n",
    "train_malignant_path = os.path.join(train_path, 'malignant')\n",
    "test_benign_path = os.path.join(test_path, 'benign')\n",
    "test_malignant_path = os.path.join(test_path, 'malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking dataset structure...\")\n",
    "print(f\"Dataset folder exists: {os.path.exists(dataset_path)}\")\n",
    "print(f\"Train folder exists: {os.path.exists(train_path)}\")\n",
    "print(f\"Test folder exists: {os.path.exists(test_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c327703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrain folders:\")\n",
    "print(f\"  Train/Benign exists: {os.path.exists(train_benign_path)}\")\n",
    "print(f\"  Train/Malignant exists: {os.path.exists(train_malignant_path)}\")\n",
    "\n",
    "print(\"\\nTest folders:\")\n",
    "print(f\"  Test/Benign exists: {os.path.exists(test_benign_path)}\")\n",
    "print(f\"  Test/Malignant exists: {os.path.exists(test_malignant_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da967",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_count = len([f for f in os.listdir(train_benign_path) if f.endswith('.jpg')])\n",
    "print(f\"  Train/Benign images: {train_benign_count}\")\n",
    "\n",
    "train_malignant_count = len([f for f in os.listdir(train_malignant_path) if f.endswith('.jpg')])\n",
    "print(f\"  Train/Malignant images: {train_malignant_count}\")\n",
    "\n",
    "test_benign_count = len([f for f in os.listdir(test_benign_path) if f.endswith('.jpg')])\n",
    "print(f\"  Test/Benign images: {test_benign_count}\")\n",
    "\n",
    "test_malignant_count = len([f for f in os.listdir(test_malignant_path) if f.endswith('.jpg')])\n",
    "print(f\"  Test/Malignant images: {test_malignant_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf1e48",
   "metadata": {},
   "source": [
    "Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, label, max_samples=500):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Get all jpg files\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "\n",
    "    # Randomly select max_samples files\n",
    "    if len(files) > max_samples:\n",
    "        files = random.sample(files, max_samples)\n",
    "\n",
    "    print(f\"Loading {len(files)} images from {folder_path.split('/')[-1]} folder...\")\n",
    "\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),  # Converts PIL image to tensor and normalizes to [0,1]\n",
    "    ])\n",
    "\n",
    "    for i, filename in enumerate(files):\n",
    "        try:\n",
    "            # Load and transform image\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = transform(img)\n",
    "\n",
    "            # Convert to numpy for consistency with rest of code\n",
    "            img_array = img_tensor.permute(1, 2, 0).numpy()  # CHW -> HWC\n",
    "\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"  Processed {i + 1}/{len(files)} images\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_images, train_benign_labels = load_images(train_benign_path, 0, NUM_SAMPLES)  # 0 for benign\n",
    "train_malignant_images, train_malignant_labels = load_images(train_malignant_path, 1, NUM_SAMPLES)  # 1 for malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training data\n",
    "X_train = np.concatenate([train_benign_images, train_malignant_images], axis=0)\n",
    "y_train = np.concatenate([train_benign_labels, train_malignant_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a45d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_benign_images, test_benign_labels = load_images(test_benign_path, 0, NUM_SAMPLES)  # 0 for benign\n",
    "test_malignant_images, test_malignant_labels = load_images(test_malignant_path, 1, NUM_SAMPLES)  # 1 for malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test data\n",
    "X_test = np.concatenate([test_benign_images, test_malignant_images], axis=0)\n",
    "y_test = np.concatenate([test_benign_labels, test_malignant_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36159c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Dataset Summary ===\")\n",
    "print(f\"Training set:\")\n",
    "print(f\"  Total images: {len(X_train)}\")\n",
    "print(f\"  Benign images: {np.sum(y_train == 0)}\")\n",
    "print(f\"  Malignant images: {np.sum(y_train == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61650184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Total images: {len(X_test)}\")\n",
    "print(f\"  Benign images: {np.sum(y_test == 0)}\")\n",
    "print(f\"  Malignant images: {np.sum(y_test == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d55429",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nImage specifications:\")\n",
    "print(f\"  Image shape: {X_train[0].shape}\")\n",
    "print(f\"  Pixel value range: [{X_train.min():.3f}, {X_train.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d300859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Display sample images\n",
    "def display_sample_images(X, y, title=\"Sample Images\", num_samples=6):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        idx = random.randint(0, len(X) - 1)\n",
    "        img = X[idx]\n",
    "        label = 'Malignant' if y[idx] == 1 else 'Benign'\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'{label}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10123872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from training set\n",
    "print(\"\\n=== Displaying Sample Training Images ===\")\n",
    "display_sample_images(X_train, y_train, \"Training Set - Sample Images\")\n",
    "\n",
    "print(\"\\nDataset loading completed successfully!\")\n",
    "print(\"\\nVariables created:\")\n",
    "print(\"- X_train: Training images\")\n",
    "print(\"- X_test: Test images\")\n",
    "print(\"- y_train: Training labels (0=benign, 1=malignant)\")\n",
    "print(\"- y_test: Test labels (0=benign, 1=malignant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66d1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c579856",
   "metadata": {},
   "source": [
    "Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c32686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8bc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: One-hot Encoding\n",
    "print(\"1. Converting labels to one-hot encoding...\")\n",
    "\n",
    "# Create label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform training labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert to one-hot encoding using PyTorch\n",
    "y_train_onehot = F.one_hot(torch.tensor(y_train_encoded), num_classes=2).float().numpy()\n",
    "y_test_onehot = F.one_hot(torch.tensor(y_test_encoded), num_classes=2).float().numpy()\n",
    "\n",
    "print(f\"Original labels shape: {y_train.shape}\")\n",
    "print(f\"One-hot encoded labels shape: {y_train_onehot.shape}\")\n",
    "print(f\"Label mapping: {dict(enumerate(label_encoder.classes_))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show examples\n",
    "print(f\"Example - Original: {y_train[:5]} -> One-hot: {y_train_onehot[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train_onehot,\n",
    "    test_size=0.3,           # 30% for validation\n",
    "    random_state=42,\n",
    "    stratify=y_train_encoded  # Stratified sampling to maintain class balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final training set: {len(X_train_final)} images\")\n",
    "print(f\"Validation set: {len(X_val)} images\")\n",
    "print(f\"Test set: {len(X_test)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(f\"\\nClass distribution in final training set:\")\n",
    "print(f\"  Benign: {np.sum(np.argmax(y_train_final, axis=1) == 0)}\")\n",
    "print(f\"  Malignant: {np.sum(np.argmax(y_train_final, axis=1) == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nClass distribution in validation set:\")\n",
    "print(f\"  Benign: {np.sum(np.argmax(y_val, axis=1) == 0)}\")\n",
    "print(f\"  Malignant: {np.sum(np.argmax(y_val, axis=1) == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ac5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation using PyTorch transforms\n",
    "print(\"   Setting up data augmentation...\")\n",
    "print(\"   Rotation range: 15 degrees (as mentioned in paper)\")\n",
    "\n",
    "# ImageNet normalization values for VGG19\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Create data augmentation transforms for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(15),          # Rotate images by up to 15 degrees\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # Flip images horizontally\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Color jittering\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=0.1),  # Translation and shear\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),  # VGG19 ImageNet normalization\n",
    "])\n",
    "\n",
    "# Validation and test transforms (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),  # VGG19 ImageNet normalization\n",
    "])\n",
    "\n",
    "print(\"Data augmentation parameters:\")\n",
    "print(f\"  - Rotation range: 15°\")\n",
    "print(f\"  - Horizontal flip: 50% probability\")\n",
    "print(f\"  - Color jitter: brightness/contrast ±10%\")\n",
    "print(f\"  - Translation: ±10%\")\n",
    "print(f\"  - Shear range: 10%\")\n",
    "print(f\"  - ImageNet normalization: mean={IMAGENET_MEAN}, std={IMAGENET_STD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation and test data generators (no augmentation, only rescaling)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "val_datagen = ImageDataGenerator(rescale=1.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0)\n",
    "\n",
    "print(\"Data augmentation parameters:\")\n",
    "print(f\"  - Rotation range: 15°\")\n",
    "print(f\"  - Width/Height shift: 10%\")\n",
    "print(f\"  - Horizontal flip: Yes\")\n",
    "print(f\"  - Zoom range: 10%\")\n",
    "print(f\"  - Shear range: 10%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets and dataloaders\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SkinCancerDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert numpy array to uint8 for PIL transforms\n",
    "        if image.max() <= 1.0:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image).permute(2, 0, 1).float() / 255.0  # HWC -> CHW and normalize\n",
    "\n",
    "        # Convert one-hot label to class index for PyTorch\n",
    "        if len(label.shape) > 0 and label.shape[0] > 1:  # one-hot encoded\n",
    "            label = torch.tensor(np.argmax(label)).long()\n",
    "        else:\n",
    "            label = torch.tensor(label).long()\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SkinCancerDataset(X_train_final, y_train_final, transform=train_transform)\n",
    "val_dataset = SkinCancerDataset(X_val, y_val, transform=val_test_transform)\n",
    "test_dataset = SkinCancerDataset(X_test, y_test_onehot, transform=val_test_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"   Data loaders created with batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Training batches per epoch: {len(train_loader)}\")\n",
    "print(f\"   Validation batches per epoch: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcc344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize augmented images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_augmented_images(dataloader, num_images=6):\n",
    "    \"\"\"Display original and augmented images\"\"\"\n",
    "    # Get a batch from the dataloader\n",
    "    dataiter = iter(dataloader)\n",
    "    batch_images, batch_labels = next(dataiter)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(min(num_images, len(batch_images))):\n",
    "        # Convert tensor to numpy for display (CHW -> HWC)\n",
    "        img = batch_images[i].permute(1, 2, 0).numpy()\n",
    "        # Ensure values are in [0,1] range for display\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        label = batch_labels[i].item()\n",
    "        label_name = 'Malignant' if label == 1 else 'Benign'\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Augmented {label_name}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle('Sample Augmented Training Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"   Displaying sample augmented images...\")\n",
    "show_augmented_images(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b61d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset the dataloader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Summary\n",
    "print(\"\\n=== Dataset Preparation Summary ===\")\n",
    "print(\"✓ Labels converted to one-hot encoding\")\n",
    "print(\"✓ Data split using stratified sampling (70% train, 30% validation)\")\n",
    "print(\"✓ Data augmentation applied to training set\")\n",
    "print(\"✓ Data generators created for training, validation, and testing\")\n",
    "print(\"\\nDataset is ready for VGG-19 model training!\")\n",
    "\n",
    "print(\"\\nVariables available for next step:\")\n",
    "print(\"- train_generator: Training data with augmentation\")\n",
    "print(\"- val_generator: Validation data\")\n",
    "print(\"- test_generator: Test data\")\n",
    "print(\"- X_train_final, y_train_final: Final training arrays\")\n",
    "print(\"- X_val, y_val: Validation arrays\")\n",
    "print(\"- X_test, y_test_onehot: Test arrays with one-hot labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af3789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eba1e776",
   "metadata": {},
   "source": [
    "Transfer Learning using VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load pre-trained VGG-19 base model\n",
    "print(\"1. Loading pre-trained VGG-19 base model...\")\n",
    "\n",
    "# Load VGG-19 with pre-trained ImageNet weights\n",
    "base_model = models.vgg19(weights='IMAGENET1K_V1')\n",
    "\n",
    "print(f\"VGG-19 base model loaded successfully\")\n",
    "print(f\"Original classifier: {base_model.classifier}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Freeze the base model layers\n",
    "print(\"\\n2. Freezing base model layers...\")\n",
    "\n",
    "# Freeze all parameters in features (convolutional layers)\n",
    "for param in base_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(f\"Base model features frozen\")\n",
    "print(f\"Total feature layers: {len(list(base_model.features.children()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3600124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the complete model with custom top layers\n",
    "print(\"\\n3. Building complete model with custom layers...\")\n",
    "\n",
    "class VGG19SkinCancer(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=2):\n",
    "        super(VGG19SkinCancer, self).__init__()\n",
    "\n",
    "        # Use VGG-19 features (convolutional layers)\n",
    "        self.features = base_model.features\n",
    "\n",
    "        # Adaptive pooling to handle different input sizes\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        # Custom classifier as described in paper\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.25),                    # Dropout for regularization (0.25 as mentioned in paper)\n",
    "            nn.Linear(25088, 128),               # Dense layer with 128 neurons\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.25),                    # Dropout after first dense layer\n",
    "            nn.Linear(128, 64),                  # Dense layer with 64 neurons\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, num_classes),          # Output layer with 2 neurons (binary classification)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create the complete model\n",
    "model = VGG19SkinCancer(base_model, num_classes=2)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"✓ Model architecture created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Display model summary\n",
    "print(\"\\n4. Model Summary:\")\n",
    "print(model)\n",
    "\n",
    "# Create a sample input to get model statistics\n",
    "sample_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "with torch.no_grad():\n",
    "    sample_output = model(sample_input)\n",
    "\n",
    "print(f\"\\nModel input shape: {sample_input.shape}\")\n",
    "print(f\"Model output shape: {sample_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "non_trainable_params = total_params - trainable_params\n",
    "\n",
    "print(f\"\\nParameter Summary:\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {non_trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Setup optimizer and loss function\n",
    "print(\"\\n5. Setting up optimizer and loss function...\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n",
    "print(\"✓ Optimizer and loss function configured\")\n",
    "print(\"  - Loss function: CrossEntropyLoss\")\n",
    "print(\"  - Optimizer: Adam (lr=0.001)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Display model architecture details\n",
    "print(\"\\n6. Model Architecture Details:\")\n",
    "print(\"=\"*50)\n",
    "print(\"VGG-19 Base Model (Frozen):\")\n",
    "print(\"- Pre-trained on ImageNet\")\n",
    "print(\"- 19 layers deep\")\n",
    "print(\"- Convolutional and MaxPooling layers\")\n",
    "print(\"- Features extracted using adaptive pooling\")\n",
    "\n",
    "print(\"\\nCustom Classifier (Trainable):\")\n",
    "print(\"- Flatten layer: Convert 2D to 1D\")\n",
    "print(\"- Dropout: 0.25 (regularization)\")\n",
    "print(\"- Linear layer: 25088 -> 128 neurons, ReLU activation\")\n",
    "print(\"- Dropout: 0.25 (regularization)\")\n",
    "print(\"- Linear layer: 128 -> 64 neurons, ReLU activation\")\n",
    "print(\"- Output layer: 64 -> 2 neurons, no activation (raw logits)\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c6c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Model architecture visualization (PyTorch)\n",
    "print(\"\\n7. Model Architecture:\")\n",
    "print(\"PyTorch model architecture visualization:\")\n",
    "print(f\"- Model device: {next(model.parameters()).device}\")\n",
    "print(f\"- Model mode: {'Training' if model.training else 'Evaluation'}\")\n",
    "\n",
    "# You can use torchsummary or torchinfo for detailed model summary if installed\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    print(\"\\nDetailed model summary:\")\n",
    "    summary(model, (3, 224, 224))\n",
    "except ImportError:\n",
    "    print(\"\\n! torchsummary not installed. Install with: pip install torchsummary\")\n",
    "    print(\"Model structure displayed above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Setup training callbacks/schedulers\n",
    "print(\"\\n8. Setting up training schedulers...\")\n",
    "\n",
    "# Learning rate scheduler (equivalent to ReduceLROnPlateau)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-4\n",
    ")\n",
    "\n",
    "# Early stopping parameters (will be implemented in training loop)\n",
    "early_stopping_patience = 5\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"✓ Training schedulers configured:\")\n",
    "print(\"  - Learning rate reduction: factor=0.2, patience=3\")\n",
    "print(\"  - Early stopping: patience=5\")\n",
    "print(\"  - Best model weights will be saved automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Display training information\n",
    "print(\"\\n9. Training Setup Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Model is ready for training with:\")\n",
    "print(f\"- Model device: {device}\")\n",
    "print(f\"- Loss function: CrossEntropyLoss\")\n",
    "print(f\"- Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"- Scheduler: ReduceLROnPlateau\")\n",
    "\n",
    "print(f\"\\nTraining data ready:\")\n",
    "print(f\"- Training samples: {len(train_dataset)}\")\n",
    "print(f\"- Validation samples: {len(val_dataset)}\")\n",
    "print(f\"- Test samples: {len(test_dataset)}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "print(\"\\nNext step: Train the model!\")\n",
    "print(\"Variables available:\")\n",
    "print(\"- model: Complete VGG-19 transfer learning model\")\n",
    "print(\"- optimizer: Adam optimizer\")\n",
    "print(\"- criterion: CrossEntropyLoss\")\n",
    "print(\"- scheduler: Learning rate scheduler\")\n",
    "print(\"- train_loader: Training data\")\n",
    "print(\"- val_loader: Validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee2c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set training parameters as mentioned in paper\n",
    "print(\"1. Setting training parameters...\")\n",
    "\n",
    "LEARNING_RATE = 0.0001  # Learning rate set to 0.0001 as mentioned in paper\n",
    "EPOCHS = 15             # Number of iterations set to 15 as mentioned in paper\n",
    "BATCH_SIZE = 32         # Batch size set to 32 as mentioned in paper\n",
    "\n",
    "print(f\"Training parameters:\")\n",
    "print(f\"- Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"- Epochs: {EPOCHS}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Optimizer: Adam\")\n",
    "print(f\"- Loss function: CrossEntropyLoss\")\n",
    "print(f\"- Metric: Accuracy\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Update optimizer with specified learning rate\n",
    "print(\"\\n2. Updating optimizer with specified parameters...\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Adam optimizer with lr=0.0001\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
    "\n",
    "print(\"✓ Optimizer updated successfully\")\n",
    "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Loss function: CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72239a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Display training setup\n",
    "steps_per_epoch = len(train_loader)\n",
    "validation_steps = len(val_loader)\n",
    "\n",
    "print(f\"\\nTraining setup:\")\n",
    "print(f\"- Training samples: {len(train_dataset)}\")\n",
    "print(f\"- Validation samples: {len(val_dataset)}\")\n",
    "print(f\"- Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"- Validation steps: {validation_steps}\")\n",
    "print(f\"- Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d42c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Start training\n",
    "print(f\"\\n3. Starting model training for {EPOCHS} epochs...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Record training start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate averages\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Learning rate scheduler step\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_vgg19_skin_cancer_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "        break\n",
    "\n",
    "# Record training end time\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n✓ Training completed!\")\n",
    "print(f\"Total training time: {training_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Display training results\n",
    "print(f\"\\n4. Training Results Summary:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get final epoch results\n",
    "final_train_acc = history['train_acc'][-1]\n",
    "final_val_acc = history['val_acc'][-1]\n",
    "final_train_loss = history['train_loss'][-1]\n",
    "final_val_loss = history['val_loss'][-1]\n",
    "\n",
    "print(f\"Final Training Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ecef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Plot training history\n",
    "print(f\"   Plotting training history...\")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation accuracy and loss\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    epochs = range(1, len(history['train_acc']) + 1)\n",
    "\n",
    "    # Plot accuracy\n",
    "    ax1.plot(epochs, history['train_acc'], label='Training Accuracy', marker='o')\n",
    "    ax1.plot(epochs, history['val_acc'], label='Validation Accuracy', marker='s')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot loss\n",
    "    ax2.plot(epochs, history['train_loss'], label='Training Loss', marker='o')\n",
    "    ax2.plot(epochs, history['val_loss'], label='Validation Loss', marker='s')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef002ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluate model on test set\n",
    "print(f\"\\n6. Evaluating model on test set...\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_vgg19_skin_cancer_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_acc = round(test_accuracy * 100, 2)\n",
    "print(vgg19_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Display detailed training metrics\n",
    "print(f\"\\n7. Detailed Training Metrics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Epoch':<6} {'Train Acc':<10} {'Val Acc':<10} {'Train Loss':<12} {'Val Loss':<10}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for i in range(len(history['train_acc'])):\n",
    "    epoch = i + 1\n",
    "    train_acc = history['train_acc'][i]\n",
    "    val_acc = history['val_acc'][i]\n",
    "    train_loss = history['train_loss'][i]\n",
    "    val_loss = history['val_loss'][i]\n",
    "\n",
    "    print(f\"{epoch:<6} {train_acc:<10.4f} {val_acc:<10.4f} {train_loss:<12.4f} {val_loss:<10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Save the trained model\n",
    "print(f\"\\n8. Saving the trained model...\")\n",
    "\n",
    "# Save complete model\n",
    "torch.save(model.state_dict(), 'vgg19_skin_cancer_model.pth')\n",
    "# Also save the complete model for easy loading\n",
    "torch.save(model, 'vgg19_skin_cancer_complete_model.pth')\n",
    "\n",
    "print(\"✓ Model saved as 'vgg19_skin_cancer_model.pth' (state dict)\")\n",
    "print(\"✓ Complete model saved as 'vgg19_skin_cancer_complete_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Training summary\n",
    "print(f\"\\n9. Training Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"✓ Model trained successfully for {len(history['train_acc'])} epochs\")\n",
    "print(f\"✓ Training time: {training_time/60:.2f} minutes\")\n",
    "print(f\"✓ Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"✓ Final test accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "if test_accuracy >= 0.85:  # Check if close to paper's 88% accuracy\n",
    "    print(f\"✓ Model achieved good performance (≥85% accuracy)\")\n",
    "    print(\"✓ Model is ready for adversarial attack testing!\")\n",
    "else:\n",
    "    print(f\"! Model accuracy is below 85%. Consider:\")\n",
    "    print(\"  - Training for more epochs\")\n",
    "    print(\"  - Adjusting learning rate\")\n",
    "    print(\"  - Fine-tuning hyperparameters\")\n",
    "\n",
    "print(f\"\\nVariables created:\")\n",
    "print(\"- history: Training history with metrics\")\n",
    "print(\"- model: Trained VGG-19 model\")\n",
    "print(f\"- test_accuracy: Final test accuracy ({test_accuracy:.4f})\")\n",
    "\n",
    "print(f\"\\nNext step: Implement FGSM adversarial attack!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb042f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad44284a",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b03ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make predictions on test set\n",
    "print(\"1. Making predictions on test set...\")\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "test_true_classes = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Making predictions\"):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        test_predictions.extend(probabilities.cpu().numpy())\n",
    "        test_true_classes.extend(labels.numpy())\n",
    "\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_pred_classes = np.argmax(test_predictions, axis=1)\n",
    "test_true_classes = np.array(test_true_classes)\n",
    "\n",
    "print(f\"✓ Predictions completed\")\n",
    "print(f\"Test samples: {len(test_pred_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names\n",
    "class_names = ['Benign', 'Malignant']\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(\n",
    "    test_true_classes,\n",
    "    test_pred_classes,\n",
    "    target_names=class_names,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Create formatted classification report table\n",
    "print(f\"Classification Results of the Trained Model\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Class':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for class_name in class_names:\n",
    "    precision = report[class_name]['precision'] * 100\n",
    "    recall = report[class_name]['recall'] * 100\n",
    "    f1 = report[class_name]['f1-score'] * 100\n",
    "    support = int(report[class_name]['support'])\n",
    "\n",
    "    print(f\"{class_name:<12} {precision:<12.0f}% {recall:<12.0f}% {f1:<12.0f}% {support:<12}\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = report['accuracy'] * 100\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Overall':<12} {'Accuracy:':<12} {overall_accuracy:<12.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Display detailed metrics as mentioned in paper\n",
    "print(f\"   Detailed Performance Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "precision_benign = report['Benign']['precision'] * 100\n",
    "precision_malignant = report['Malignant']['precision'] * 100\n",
    "recall_benign = report['Benign']['recall'] * 100\n",
    "recall_malignant = report['Malignant']['recall'] * 100\n",
    "f1_benign = report['Benign']['f1-score'] * 100\n",
    "f1_malignant = report['Malignant']['f1-score'] * 100\n",
    "\n",
    "print(f\"PRECISION (Model's accuracy of positive predictions):\")\n",
    "print(f\"- Benign images correctly predicted: {precision_benign:.0f}%\")\n",
    "print(f\"- Malignant images correctly predicted: {precision_malignant:.0f}%\")\n",
    "\n",
    "print(f\"\\nRECALL (Ability to find all positive instances):\")\n",
    "print(f\"- Benign recall: {recall_benign:.0f}%\")\n",
    "print(f\"- Malignant recall: {recall_malignant:.0f}%\")\n",
    "\n",
    "print(f\"\\nF1-SCORE (Percentage of positive predictions that were correct):\")\n",
    "print(f\"- Benign F1-score: {f1_benign:.0f}%\")\n",
    "print(f\"- Malignant F1-score: {f1_malignant:.0f}%\")\n",
    "\n",
    "print(f\"\\nSUPPORT (Number of actual occurrences):\")\n",
    "print(f\"- Benign images: {int(report['Benign']['support'])}\")\n",
    "print(f\"- Malignant images: {int(report['Malignant']['support'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Training Loss and Accuracy Graph (Figure 2)\n",
    "print(f\"   Creating Training Loss and Accuracy Graph (Figure 2)...\")\n",
    "\n",
    "def plot_training_results():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Fixed: Use PyTorch history format (simple dict) instead of TensorFlow history.history\n",
    "    epochs_range = range(1, len(history['train_acc']) + 1)\n",
    "\n",
    "    # Plot Training and Validation Accuracy\n",
    "    ax1.plot(epochs_range, [acc*100 for acc in history['train_acc']],\n",
    "             'b-o', label='Training Accuracy', linewidth=2, markersize=6)\n",
    "    ax1.plot(epochs_range, [acc*100 for acc in history['val_acc']],\n",
    "             'r-s', label='Validation Accuracy', linewidth=2, markersize=6)\n",
    "    ax1.set_title('Model Accuracy During Training', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Number of Epochs/Iterations', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim([0, 100])\n",
    "\n",
    "    # Plot Training and Validation Loss\n",
    "    ax2.plot(epochs_range, history['train_loss'],\n",
    "             'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "    ax2.plot(epochs_range, history['val_loss'],\n",
    "             'r-s', label='Validation Loss', linewidth=2, markersize=6)\n",
    "    ax2.set_title('Model Loss During Training', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Number of Epochs/Iterations', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Training Loss and Accuracy Graph', fontsize=16, y=1.02)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create Confusion Matrix (Figure 3)\n",
    "print(f\"   Creating Confusion Matrix (Figure 3)...\")\n",
    "\n",
    "def plot_confusion_matrix():\n",
    "    \"\"\"Create Figure 3: Confusion matrix\"\"\"\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(test_true_classes, test_pred_classes)\n",
    "\n",
    "    # Create confusion matrix plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Use seaborn for better visualization\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                annot_kws={'size': 16}, cbar_kws={'label': 'Number of Images'})\n",
    "\n",
    "    plt.title('Confusion Matrix of the Model', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Labels', fontsize=14)\n",
    "    plt.ylabel('True Labels', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12, rotation=0)\n",
    "\n",
    "    # Add percentage annotations\n",
    "    total = cm.sum()\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            percentage = (cm[i, j] / total) * 100\n",
    "            plt.text(j+0.5, i+0.7, f'({percentage:.1f}%)',\n",
    "                    ha='center', va='center', fontsize=12, color='red')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return cm\n",
    "\n",
    "cm = plot_confusion_matrix()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2bf86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Calculate and display confusion matrix metrics\n",
    "print(f\"Confusion Matrix Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate rates as mentioned in paper\n",
    "benign_true_positive_rate = (cm[0,0] / (cm[0,0] + cm[0,1])) * 100\n",
    "benign_false_positive_rate = (cm[0,1] / (cm[0,0] + cm[0,1])) * 100\n",
    "\n",
    "malignant_true_negative_rate = (cm[1,1] / (cm[1,0] + cm[1,1])) * 100\n",
    "malignant_false_negative_rate = (cm[1,0] / (cm[1,0] + cm[1,1])) * 100\n",
    "\n",
    "print(f\"BENIGN Classification:\")\n",
    "print(f\"- True Positive Rate: {benign_true_positive_rate:.0f}% ({cm[0,0]} images)\")\n",
    "print(f\"- False Positive Rate: {benign_false_positive_rate:.0f}% ({cm[0,1]} images)\")\n",
    "\n",
    "print(f\"\\nMALIGNANT Classification:\")\n",
    "print(f\"- True Negative Rate: {malignant_true_negative_rate:.0f}% ({cm[1,1]} images)\")\n",
    "print(f\"- False Negative Rate: {malignant_false_negative_rate:.0f}% ({cm[1,0]} images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Summary of Results\n",
    "print(f\"RESULTS SUMMARY:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Overall Model Accuracy: {overall_accuracy:.0f}%\")\n",
    "print(f\"✓ High classification accuracy achieved\")\n",
    "print(f\"✓ Model demonstrates strong performance on both classes\")\n",
    "print(f\"✓ Training and validation curves show good learning progression\")\n",
    "print(f\"✓ Minimal overfitting observed\")\n",
    "\n",
    "# Create summary table\n",
    "summary_data = {\n",
    "    'Metric': ['Precision', 'Recall', 'F1-Score', 'Support'],\n",
    "    'Benign': [f\"{precision_benign:.0f}%\", f\"{recall_benign:.0f}%\",\n",
    "               f\"{f1_benign:.0f}%\", f\"{int(report['Benign']['support'])}\"],\n",
    "    'Malignant': [f\"{precision_malignant:.0f}%\", f\"{recall_malignant:.0f}%\",\n",
    "                  f\"{f1_malignant:.0f}%\", f\"{int(report['Malignant']['support'])}\"]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(f\"\\nSUMMARY TABLE:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n✓ Model is ready for adversarial attack testing!\")\n",
    "print(f\"✓ Current accuracy ({overall_accuracy:.0f}%) will be compared against\")\n",
    "print(f\"  post-attack accuracy to demonstrate FGSM impact\")\n",
    "\n",
    "print(f\"\\nVariables created:\")\n",
    "print(\"- test_pred_classes: Model predictions on test set\")\n",
    "print(\"- test_true_classes: True labels for test set\")\n",
    "print(\"- report: Classification report dictionary\")\n",
    "print(\"- cm: Confusion matrix\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementing FGSM Attack to the Trained CNN\n",
    " In Part 1, we focused on training the VGG-19 model with a\n",
    " medical dataset to accurately classify the benign and malignant\n",
    " skin-cancer images. In Part 2, we will focus on generating the\n",
    " adversarial attack and implementing it to the system.\n",
    "\n",
    " 1) Generating Image Adversary: To implement the attack,\n",
    " we first generated an image adversary and recorded our\n",
    " gradients. We used our model to make predictions on the input\n",
    " image and then compute the loss. From there, we calculate the\n",
    " gradient of loss and compute the sign of the gradient. Then, we\n",
    " construct the image adversary by adding the image with the\n",
    " sign of the gradient. Fig. 1 illustrates the difference between\n",
    " the original image and an adversarial image from a sample\n",
    " image of the dataset.\n",
    " Fig. 1. Comparison of the original image and an adversarial image.\n",
    " After the adversarial image was created, it was sent to the\n",
    " trained model to classify the images. The evaluation of the\n",
    " model after the attack, is reported in Section IV.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cc8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Part 2 - Implementing FGSM Attack to the Trained CNN\n",
    "\n",
    "def create_adversarial_pattern(input_image, input_label, model, device):\n",
    "    \"\"\"\n",
    "    Create adversarial pattern using FGSM attack\n",
    "    \"\"\"\n",
    "    # Ensure input requires gradients\n",
    "    input_image = input_image.clone().detach().requires_grad_(True).to(device)\n",
    "    input_label = input_label.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_image)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.cross_entropy(output, input_label)\n",
    "\n",
    "    # Backward pass to get gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Get the sign of the gradients to create the perturbation\n",
    "    gradient = input_image.grad.data\n",
    "    signed_grad = gradient.sign()\n",
    "\n",
    "    return signed_grad\n",
    "\n",
    "def generate_adversarial_examples(model, test_loader, device, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Generate adversarial examples using FGSM attack\n",
    "\n",
    "    Args:\n",
    "        model: Trained CNN model\n",
    "        test_loader: PyTorch DataLoader for test data\n",
    "        device: Device (cpu/cuda)\n",
    "        epsilon: Perturbation magnitude\n",
    "\n",
    "    Returns:\n",
    "        adversarial_images: Generated adversarial examples\n",
    "        original_images: Original images\n",
    "        true_labels: True labels\n",
    "    \"\"\"\n",
    "    print(f\"Generating adversarial examples with epsilon = {epsilon}...\")\n",
    "\n",
    "    model.eval()\n",
    "    adversarial_images = []\n",
    "    original_images = []\n",
    "    true_labels = []\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(test_loader, desc=\"Generating adversarial examples\")):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Create adversarial pattern\n",
    "        perturbations = create_adversarial_pattern(images, labels, model, device)\n",
    "\n",
    "        # Create adversarial images\n",
    "        adversarial_batch = images + epsilon * perturbations\n",
    "\n",
    "        # Clip to valid pixel range [0, 1]\n",
    "        adversarial_batch = torch.clamp(adversarial_batch, 0, 1)\n",
    "\n",
    "        # Store results\n",
    "        adversarial_images.extend(adversarial_batch.cpu().detach().numpy())\n",
    "        original_images.extend(images.cpu().detach().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(adversarial_images), np.array(original_images), np.array(true_labels)\n",
    "\n",
    "def evaluate_adversarial_attack(model, X_original, X_adversarial, y_true, class_names, device):\n",
    "    \"\"\"\n",
    "    Evaluate the impact of adversarial attack\n",
    "\n",
    "    Args:\n",
    "        model: Trained CNN model\n",
    "        X_original: Original test images\n",
    "        X_adversarial: Adversarial test images\n",
    "        y_true: True labels\n",
    "        class_names: List of class names\n",
    "        device: Device (cpu/cuda)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EVALUATING ADVERSARIAL ATTACK IMPACT\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Get predictions for original images\n",
    "    print(\"Making predictions on original images...\")\n",
    "    original_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_original), 32):  # Process in batches\n",
    "            batch = torch.tensor(X_original[i:i+32]).to(device)\n",
    "            outputs = model(batch)\n",
    "            predictions = torch.softmax(outputs, dim=1)\n",
    "            original_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    original_predictions = np.array(original_predictions)\n",
    "    original_pred_classes = np.argmax(original_predictions, axis=1)\n",
    "\n",
    "    # Get predictions for adversarial images\n",
    "    print(\"Making predictions on adversarial images...\")\n",
    "    adversarial_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_adversarial), 32):  # Process in batches\n",
    "            batch = torch.tensor(X_adversarial[i:i+32]).to(device)\n",
    "            outputs = model(batch)\n",
    "            predictions = torch.softmax(outputs, dim=1)\n",
    "            adversarial_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    adversarial_predictions = np.array(adversarial_predictions)\n",
    "    adversarial_pred_classes = np.argmax(adversarial_predictions, axis=1)\n",
    "\n",
    "    # Calculate accuracies\n",
    "    original_accuracy = np.mean(original_pred_classes == y_true)\n",
    "    adversarial_accuracy = np.mean(adversarial_pred_classes == y_true)\n",
    "\n",
    "    print(f\"\\nOriginal Model Accuracy: {original_accuracy:.2%}\")\n",
    "    print(f\"Adversarial Model Accuracy: {adversarial_accuracy:.2%}\")\n",
    "    print(f\"Accuracy Drop: {original_accuracy - adversarial_accuracy:.2%}\")\n",
    "\n",
    "    return original_pred_classes, adversarial_pred_classes\n",
    "\n",
    "def plot_confusion_matrices(original_pred, adversarial_pred, true_labels, class_names):\n",
    "    \"\"\"\n",
    "    Plot confusion matrices for original and adversarial predictions\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Original predictions confusion matrix\n",
    "    cm_original = confusion_matrix(true_labels, original_pred)\n",
    "    sns.heatmap(cm_original, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
    "    axes[0].set_title('Confusion Matrix - Original Images')\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('Actual')\n",
    "\n",
    "    # Adversarial predictions confusion matrix\n",
    "    cm_adversarial = confusion_matrix(true_labels, adversarial_pred)\n",
    "    sns.heatmap(cm_adversarial, annot=True, fmt='d', cmap='Reds',\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
    "    axes[1].set_title('Confusion Matrix - Adversarial Images')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('Actual')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return cm_original, cm_adversarial\n",
    "\n",
    "def visualize_adversarial_examples(X_original, X_adversarial, y_true,\n",
    "                                 original_pred, adversarial_pred, class_names, n_samples=6):\n",
    "    \"\"\"\n",
    "    Visualize original vs adversarial images with predictions\n",
    "    \"\"\"\n",
    "    # Find examples where adversarial attack succeeded (changed prediction)\n",
    "    attack_success = (original_pred != adversarial_pred)\n",
    "    success_indices = np.where(attack_success)[0]\n",
    "\n",
    "    if len(success_indices) < n_samples:\n",
    "        indices = success_indices\n",
    "    else:\n",
    "        indices = np.random.choice(success_indices, n_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(2, len(indices), figsize=(15, 6))\n",
    "    if len(indices) == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        # Original image - convert from CHW to HWC for display\n",
    "        orig_img = X_original[idx].transpose(1, 2, 0)\n",
    "        axes[0, i].imshow(np.clip(orig_img, 0, 1))\n",
    "        axes[0, i].set_title(f'Original\\nTrue: {class_names[y_true[idx]]}\\n'\n",
    "                           f'Pred: {class_names[original_pred[idx]]}')\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        # Adversarial image - convert from CHW to HWC for display\n",
    "        adv_img = X_adversarial[idx].transpose(1, 2, 0)\n",
    "        axes[1, i].imshow(np.clip(adv_img, 0, 1))\n",
    "        axes[1, i].set_title(f'Adversarial\\nTrue: {class_names[y_true[idx]]}\\n'\n",
    "                           f'Pred: {class_names[adversarial_pred[idx]]}')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.suptitle('Original vs Adversarial Images Comparison', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution code\n",
    "def run_fgsm_attack(model, test_loader, device, class_names=['Benign', 'Malignant'], epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Main function to run FGSM attack\n",
    "\n",
    "    Args:\n",
    "        model: Your trained VGG-19 model\n",
    "        test_loader: PyTorch DataLoader for test data\n",
    "        device: Device (cpu/cuda)\n",
    "        class_names: List of class names\n",
    "        epsilon: Perturbation strength\n",
    "    \"\"\"\n",
    "    print(\"Starting FGSM Attack Implementation...\")\n",
    "    print(f\"Epsilon (perturbation strength): {epsilon}\")\n",
    "\n",
    "    # Step 1: Generate adversarial examples\n",
    "    X_adversarial, X_original, true_labels = generate_adversarial_examples(model, test_loader, device, epsilon)\n",
    "\n",
    "    # Step 2: Evaluate attack impact\n",
    "    original_pred, adversarial_pred = evaluate_adversarial_attack(\n",
    "        model, X_original, X_adversarial, true_labels, class_names, device\n",
    "    )\n",
    "\n",
    "    # Step 3: Plot confusion matrices\n",
    "    print(\"\\nGenerating confusion matrices...\")\n",
    "    cm_original, cm_adversarial = plot_confusion_matrices(\n",
    "        original_pred, adversarial_pred, true_labels, class_names\n",
    "    )\n",
    "\n",
    "    # Step 4: Visualize some adversarial examples\n",
    "    print(\"\\nVisualizing adversarial examples...\")\n",
    "    visualize_adversarial_examples(\n",
    "        X_original, X_adversarial, true_labels, original_pred, adversarial_pred, class_names\n",
    "    )\n",
    "\n",
    "    # Step 5: Print detailed classification report\n",
    "    print(\"\\nClassification Report - Original Images:\")\n",
    "    print(classification_report(true_labels, original_pred, target_names=class_names))\n",
    "\n",
    "    print(\"\\nClassification Report - Adversarial Images:\")\n",
    "    print(classification_report(true_labels, adversarial_pred, target_names=class_names))\n",
    "\n",
    "    return X_adversarial, original_pred, adversarial_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration with your existing code\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART 2: IMPLEMENTING FGSM ATTACK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Run FGSM attack with different epsilon values\n",
    "epsilon_values = [0.5, 1.0, 2.55, 3.815]  # Different perturbation strengths\n",
    "results_data = []\n",
    "\n",
    "for eps in epsilon_values:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Testing with Epsilon = {eps}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    # Run FGSM attack\n",
    "    X_adversarial, original_pred, adversarial_pred = run_fgsm_attack(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        class_names=['Benign', 'Malignant'],\n",
    "        epsilon=eps\n",
    "    )\n",
    "\n",
    "    # Get true labels from the attack function\n",
    "    _, _, true_labels = generate_adversarial_examples(model, test_loader, device, eps)\n",
    "\n",
    "    # Calculate metrics similar to the paper\n",
    "    original_accuracy = np.mean(original_pred == true_labels) * 100\n",
    "    adversarial_accuracy = np.mean(adversarial_pred == true_labels) * 100\n",
    "\n",
    "    results_data.append({\n",
    "        'epsilon': eps,\n",
    "        'original_accuracy': original_accuracy,\n",
    "        'adversarial_accuracy': adversarial_accuracy,\n",
    "        'accuracy_drop': original_accuracy - adversarial_accuracy\n",
    "    })\n",
    "\n",
    "    print(f\"\\nSUMMARY for Epsilon = {eps}:\")\n",
    "    print(f\"Original Accuracy: {original_accuracy:.0f}%\")\n",
    "    print(f\"Adversarial Accuracy: {adversarial_accuracy:.0f}%\")\n",
    "    print(f\"Accuracy Drop: {original_accuracy - adversarial_accuracy:.0f}%\")\n",
    "\n",
    "# Additional analysis: Attack success rate\n",
    "def analyze_attack_success(original_pred, adversarial_pred, true_labels, class_names):\n",
    "    \"\"\"\n",
    "    Analyze attack success rate per class\n",
    "    \"\"\"\n",
    "    print(\"\\nATTACK SUCCESS ANALYSIS:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_mask = (true_labels == i)\n",
    "        class_original = original_pred[class_mask]\n",
    "        class_adversarial = adversarial_pred[class_mask]\n",
    "\n",
    "        # Originally correctly classified\n",
    "        correctly_classified = (class_original == i)\n",
    "\n",
    "        # Among correctly classified, how many became misclassified\n",
    "        if np.sum(correctly_classified) > 0:\n",
    "            attack_success = np.sum(class_adversarial[correctly_classified] != i)\n",
    "            success_rate = attack_success / np.sum(correctly_classified) * 100\n",
    "            print(f\"{class_name}: {attack_success}/{np.sum(correctly_classified)} \"\n",
    "                  f\"({success_rate:.1f}%) successfully attacked\")\n",
    "\n",
    "# Run attack success analysis for the last epsilon value\n",
    "analyze_attack_success(original_pred, adversarial_pred, true_labels, ['Benign', 'Malignant'])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FGSM ATTACK IMPLEMENTATION COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4185dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for plotting\n",
    "epsilons = [r['epsilon'] for r in results_data]\n",
    "original_accs = [r['original_accuracy'] for r in results_data]\n",
    "adversarial_accs = [r['adversarial_accuracy'] for r in results_data]\n",
    "accuracy_drops = [r['accuracy_drop'] for r in results_data]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42052fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('FGSM Attack Impact on Medical Image Classification Model', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Chart 1: Side-by-side comparison\n",
    "x_pos = np.arange(len(epsilons))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x_pos - width/2, original_accs, width,\n",
    "               label='Before Attack', color='#28a745', alpha=0.8, edgecolor='black')\n",
    "bars2 = ax1.bar(x_pos + width/2, adversarial_accs, width,\n",
    "               label='After Attack', color='#dc3545', alpha=0.8, edgecolor='black')\n",
    "\n",
    "ax1.set_xlabel('Epsilon Values', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('Model Accuracy: Before vs After FGSM Attack', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels([f'ε={eps}' for eps in epsilons])\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_ylim(0, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{height:.0f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{height:.0f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Chart 2: Accuracy drop\n",
    "colors = plt.cm.Reds(np.linspace(0.4, 0.8, len(epsilons)))\n",
    "bars3 = ax2.bar(epsilons, accuracy_drops, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax2.set_xlabel('Epsilon Values', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy Drop (%)', fontsize=12)\n",
    "ax2.set_title('Accuracy Drop Due to FGSM Attack', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, bar in enumerate(bars3):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height:.0f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Chart 3: Line plot\n",
    "ax3.plot(epsilons, original_accs, 'o-', color='#28a745',\n",
    "         linewidth=3, markersize=10, label='Before Attack', markeredgecolor='black')\n",
    "ax3.plot(epsilons, adversarial_accs, 's-', color='#dc3545',\n",
    "         linewidth=3, markersize=10, label='After Attack', markeredgecolor='black')\n",
    "ax3.set_xlabel('Epsilon Values', fontsize=12)\n",
    "ax3.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax3.set_title('Attack Effectiveness Trend', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=12)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(0, 100)\n",
    "\n",
    "# Chart 4: Attack impact percentage\n",
    "impact_percentages = [(orig - adv) / orig * 100 for orig, adv in zip(original_accs, adversarial_accs)]\n",
    "bars4 = ax4.bar(epsilons, impact_percentages, color='#ff6b35', alpha=0.8, edgecolor='black')\n",
    "ax4.set_xlabel('Epsilon Values', fontsize=12)\n",
    "ax4.set_ylabel('Relative Impact (%)', fontsize=12)\n",
    "ax4.set_title('Relative Attack Impact', fontsize=14, fontweight='bold')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, bar in enumerate(bars4):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a simple comparison chart (similar to your reference image)\n",
    "fig2, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Using the most impactful epsilon for comparison (usually the largest one)\n",
    "max_impact_idx = np.argmax(accuracy_drops)\n",
    "before_acc = original_accs[max_impact_idx]\n",
    "after_acc = adversarial_accs[max_impact_idx]\n",
    "eps_val = epsilons[max_impact_idx]\n",
    "\n",
    "categories = ['Before FGSM Attack', f'After FGSM Attack\\n(ε={eps_val})']\n",
    "accuracies = [before_acc, after_acc]\n",
    "colors = ['#2E86AB', '#F24236']\n",
    "\n",
    "bars = ax.bar(categories, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax.set_ylabel('Model Accuracy (%)', fontsize=14)\n",
    "ax.set_title(f'FGSM Attack Impact on Medical Image Classification\\n(Epsilon = {eps_val})',\n",
    "             fontsize=16, fontweight='bold')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{height:.0f}%', ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY TABLE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Epsilon':<10} {'Original Acc':<15} {'Adversarial Acc':<18} {'Accuracy Drop':<15} {'Relative Impact'}\")\n",
    "print(\"-\" * 70)\n",
    "for i, eps in enumerate(epsilons):\n",
    "    rel_impact = impact_percentages[i]\n",
    "    print(f\"{eps:<10} {original_accs[i]:<15.1f}% {adversarial_accs[i]:<18.1f}% \"\n",
    "          f\"{accuracy_drops[i]:<15.1f}% {rel_impact:<15.1f}%\")\n",
    "\n",
    "print(f\"\\n📊 KEY FINDINGS:\")\n",
    "print(f\"   • Model is vulnerable to FGSM attacks\")\n",
    "print(f\"   • Worst case: {max(accuracy_drops):.0f}% accuracy drop at ε={epsilons[np.argmax(accuracy_drops)]}\")\n",
    "print(f\"   • Model accuracy degraded from {original_accs[0]:.0f}% to {min(adversarial_accs):.0f}%\")\n",
    "print(f\"   • Attack effectiveness increases with epsilon value\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 2: Check for saved model or use existing model\n",
    "import os\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if os.path.exists('vgg19_skin_cancer_model.pth'):\n",
    "    print(\"Loading the saved model state dict...\")\n",
    "    # Create model architecture first\n",
    "    if 'model' not in locals():\n",
    "        base_model = models.vgg19(weights='IMAGENET1K_V1')\n",
    "        model = VGG19SkinCancer(base_model, num_classes=2)\n",
    "\n",
    "    model.load_state_dict(torch.load('vgg19_skin_cancer_model.pth', map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "elif os.path.exists('vgg19_skin_cancer_complete_model.pth'):\n",
    "    print(\"Loading the complete saved model...\")\n",
    "    model = torch.load('vgg19_skin_cancer_complete_model.pth', map_location=device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(\"✓ Complete model loaded successfully\")\n",
    "else:\n",
    "    print(\"Saved model not found. Checking if model exists in memory...\")\n",
    "    try:\n",
    "        # Check if model variable already exists from previous training\n",
    "        print(f\"Model device: {next(model.parameters()).device}\")\n",
    "        print(\"✓ Using existing model from memory\")\n",
    "    except (NameError, RuntimeError):\n",
    "        print(\"❌ No model found!\")\n",
    "        print(\"You need to either:\")\n",
    "        print(\"1. Re-run your model training code, OR\")\n",
    "        print(\"2. Load the model from correct path\")\n",
    "        print(\"\\nAvailable files in current directory:\")\n",
    "        for file in os.listdir('.'):\n",
    "            if file.endswith('.pth') or 'model' in file.lower():\n",
    "                print(f\"  - {file}\")\n",
    "        raise Exception(\"Model not available\")\n",
    "\n",
    "# Step 3: Your test data is already available\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test_onehot.shape}\")\n",
    "print(\"✓ Using existing test data from dataset preparation\")\n",
    "\n",
    "# Step 4: Prepare test data in the same way as during training\n",
    "print(\"\\nPreparing test data...\")\n",
    "\n",
    "# Check original data range\n",
    "print(f\"Original X_test range: [{X_test.min():.3f}, {X_test.max():.3f}]\")\n",
    "\n",
    "# Normalize the same way you did during training\n",
    "# CRITICAL: This must match your training normalization!\n",
    "if X_test.max() > 1.0:\n",
    "    X_test_normalized = X_test.astype(np.float32) / 255.0\n",
    "    print(\"✓ Applied /255.0 normalization\")\n",
    "else:\n",
    "    X_test_normalized = X_test.astype(np.float32)\n",
    "    print(\"✓ Data already normalized\")\n",
    "\n",
    "print(f\"Normalized X_test range: [{X_test_normalized.min():.4f}, {X_test_normalized.max():.4f}]\")\n",
    "\n",
    "# Step 5: Labels are already one-hot encoded, convert to class indices for PyTorch\n",
    "print(f\"One-hot labels shape: {y_test_onehot.shape}\")\n",
    "test_labels_indices = np.argmax(y_test_onehot, axis=1)\n",
    "print(\"✓ Labels converted from one-hot to class indices for PyTorch\")\n",
    "\n",
    "# Step 6: Verify model performance on clean data\n",
    "print(\"\\nVerifying model performance on clean test data...\")\n",
    "\n",
    "# Convert to PyTorch tensors and test\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Process in batches to avoid memory issues\n",
    "    batch_size = 32\n",
    "    for i in range(0, len(X_test_normalized), batch_size):\n",
    "        batch_images = torch.tensor(X_test_normalized[i:i+batch_size]).permute(0, 3, 1, 2).to(device)  # HWC -> CHW\n",
    "        batch_labels = torch.tensor(test_labels_indices[i:i+batch_size]).to(device)\n",
    "\n",
    "        outputs = model(batch_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += batch_labels.size(0)\n",
    "        test_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "print(f\"Clean test accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Step 7: Basic model info\n",
    "print(f\"\\nModel summary:\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"Model mode: {'Training' if model.training else 'Evaluation'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"READY FOR FGSM ATTACK TESTING\")\n",
    "print(\"=\"*50)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick diagnostic\n",
    "print(\"=== DIAGNOSTIC ===\")\n",
    "print(f\"1. Data range: [{X_test_normalized.min():.4f}, {X_test_normalized.max():.4f}]\")\n",
    "print(f\"2. Data type: {X_test_normalized.dtype}\")\n",
    "\n",
    "# Test with a tiny epsilon first\n",
    "tiny_epsilon = 0.001\n",
    "sample_size = 10\n",
    "\n",
    "# Convert sample to PyTorch format (HWC -> CHW)\n",
    "X_sample = torch.tensor(X_test_normalized[:sample_size]).permute(0, 3, 1, 2).to(device)\n",
    "y_sample = torch.tensor(test_labels_indices[:sample_size]).to(device)\n",
    "\n",
    "# Original accuracy\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    orig_outputs = model(X_sample)\n",
    "    _, orig_predicted = torch.max(orig_outputs, 1)\n",
    "    orig_acc = (orig_predicted == y_sample).float().mean().item() * 100\n",
    "\n",
    "# Tiny perturbation test\n",
    "X_tiny_adv = X_sample + tiny_epsilon\n",
    "X_tiny_adv = torch.clamp(X_tiny_adv, 0, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    tiny_outputs = model(X_tiny_adv)\n",
    "    _, tiny_predicted = torch.max(tiny_outputs, 1)\n",
    "    tiny_acc = (tiny_predicted == y_sample).float().mean().item() * 100\n",
    "\n",
    "print(f\"3. Original accuracy (sample): {orig_acc:.1f}%\")\n",
    "print(f\"4. Tiny perturbation accuracy: {tiny_acc:.1f}%\")\n",
    "\n",
    "if tiny_acc > orig_acc:\n",
    "    print(\"❌ PROBLEM: Even tiny perturbations improve accuracy!\")\n",
    "    print(\"   This suggests normalization or model issues\")\n",
    "else:\n",
    "    print(\"✅ Tiny perturbations work as expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bee1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced FGSM Diagnostic\n",
    "print(\"=== ENHANCED FGSM DIAGNOSTIC ===\")\n",
    "\n",
    "# Test with multiple epsilon values\n",
    "epsilon_values = [0.001, 0.005, 0.008, 0.01, 0.012, 0.014]\n",
    "sample_size = 50  # Use larger sample for more reliable results\n",
    "\n",
    "print(f\"Testing with sample size: {sample_size}\")\n",
    "print(f\"Epsilon values: {epsilon_values}\")\n",
    "\n",
    "# Get sample data and convert to PyTorch format\n",
    "X_sample = torch.tensor(X_test_normalized[:sample_size]).permute(0, 3, 1, 2).to(device)  # HWC -> CHW\n",
    "y_sample = torch.tensor(test_labels_indices[:sample_size]).to(device)\n",
    "\n",
    "# Get original predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    original_outputs = model(X_sample)\n",
    "    original_probs = torch.softmax(original_outputs, dim=1)\n",
    "    _, original_classes = torch.max(original_outputs, 1)\n",
    "\n",
    "original_accuracy = (original_classes == y_sample).float().mean().item() * 100\n",
    "\n",
    "print(f\"\\nOriginal accuracy on sample: {original_accuracy:.1f}%\")\n",
    "print(f\"Original confidence (avg): {original_probs.max(dim=1)[0].mean().item():.3f}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for epsilon in epsilon_values:\n",
    "    print(f\"\\n--- Testing epsilon = {epsilon} ---\")\n",
    "\n",
    "    # Generate adversarial examples for this sample\n",
    "    adversarial_images = []\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        image = X_sample[i:i+1].requires_grad_(True)\n",
    "        label = y_sample[i:i+1]\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(image)\n",
    "        loss = F.cross_entropy(output, label)\n",
    "\n",
    "        # Backward pass\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Create adversarial image\n",
    "        gradient = image.grad.data\n",
    "        signed_grad = gradient.sign()\n",
    "        adversarial_image = image + epsilon * signed_grad\n",
    "        adversarial_image = torch.clamp(adversarial_image, 0, 1)\n",
    "\n",
    "        adversarial_images.append(adversarial_image.detach())\n",
    "\n",
    "    X_adversarial = torch.cat(adversarial_images, dim=0)\n",
    "\n",
    "    # Get adversarial predictions\n",
    "    with torch.no_grad():\n",
    "        adversarial_outputs = model(X_adversarial)\n",
    "        adversarial_probs = torch.softmax(adversarial_outputs, dim=1)\n",
    "        _, adversarial_classes = torch.max(adversarial_outputs, 1)\n",
    "\n",
    "    adversarial_accuracy = (adversarial_classes == y_sample).float().mean().item() * 100\n",
    "\n",
    "    # Calculate attack success rate (originally correct -> now wrong)\n",
    "    originally_correct = (original_classes == y_sample)\n",
    "    now_wrong = (adversarial_classes != y_sample)\n",
    "    attack_success_rate = (originally_correct & now_wrong).float().sum().item() / originally_correct.float().sum().item() * 100\n",
    "\n",
    "    # Calculate average perturbation magnitude\n",
    "    avg_perturbation = (X_adversarial - X_sample).abs().mean().item()\n",
    "    max_perturbation = (X_adversarial - X_sample).abs().max().item()\n",
    "\n",
    "    results.append({\n",
    "        'epsilon': epsilon,\n",
    "        'original_acc': original_accuracy,\n",
    "        'adversarial_acc': adversarial_accuracy,\n",
    "        'accuracy_drop': original_accuracy - adversarial_accuracy,\n",
    "        'attack_success_rate': attack_success_rate,\n",
    "        'avg_perturbation': avg_perturbation,\n",
    "        'max_perturbation': max_perturbation,\n",
    "        'avg_confidence': adversarial_probs.max(dim=1)[0].mean().item()\n",
    "    })\n",
    "\n",
    "    print(f\"  Adversarial accuracy: {adversarial_accuracy:.1f}%\")\n",
    "    print(f\"  Accuracy drop: {original_accuracy - adversarial_accuracy:.1f}%\")\n",
    "    print(f\"  Attack success rate: {attack_success_rate:.1f}%\")\n",
    "    print(f\"  Avg perturbation magnitude: {avg_perturbation:.6f}\")\n",
    "    print(f\"  Avg confidence: {adversarial_probs.max(dim=1)[0].mean().item():.3f}\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"DETAILED RESULTS SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"{'Epsilon':<8} {'Orig_Acc':<10} {'Adv_Acc':<10} {'Acc_Drop':<10} {'Attack_Success':<15} {'Avg_Pert':<12} {'Confidence'}\")\n",
    "print(f\"{'-'*80}\")\n",
    "\n",
    "for r in results:\n",
    "    print(f\"{r['epsilon']:<8} {r['original_acc']:<10.1f}% {r['adversarial_acc']:<10.1f}% \"\n",
    "          f\"{r['accuracy_drop']:<10.1f}% {r['attack_success_rate']:<15.1f}% \"\n",
    "          f\"{r['avg_perturbation']:<12.6f} {r['avg_confidence']:<10.3f}\")\n",
    "\n",
    "# Check for anomalies\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"ANOMALY DETECTION\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "anomalies = []\n",
    "for i, r in enumerate(results):\n",
    "    if r['accuracy_drop'] < 0:  # Accuracy improved\n",
    "        anomalies.append(f\"ε={r['epsilon']}: Accuracy IMPROVED by {abs(r['accuracy_drop']):.1f}%\")\n",
    "    elif r['accuracy_drop'] < 5 and r['epsilon'] > 0.05:  # Large epsilon but small drop\n",
    "        anomalies.append(f\"ε={r['epsilon']}: Large epsilon but small accuracy drop ({r['accuracy_drop']:.1f}%)\")\n",
    "\n",
    "if anomalies:\n",
    "    print(\"⚠️ ANOMALIES DETECTED:\")\n",
    "    for anomaly in anomalies:\n",
    "        print(f\"  - {anomaly}\")\n",
    "else:\n",
    "    print(\"✅ No anomalies detected - FGSM behaving as expected\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "epsilons = [r['epsilon'] for r in results]\n",
    "accuracies = [r['adversarial_acc'] for r in results]\n",
    "plt.plot(epsilons, accuracies, 'ro-', linewidth=2, markersize=8)\n",
    "plt.axhline(y=original_accuracy, color='g', linestyle='--', label='Original Accuracy')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Adversarial Accuracy vs Epsilon')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "accuracy_drops = [r['accuracy_drop'] for r in results]\n",
    "plt.plot(epsilons, accuracy_drops, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy Drop (%)')\n",
    "plt.title('Accuracy Drop vs Epsilon')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "attack_success_rates = [r['attack_success_rate'] for r in results]\n",
    "plt.plot(epsilons, attack_success_rates, 'mo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Attack Success Rate (%)')\n",
    "plt.title('Attack Success Rate vs Epsilon')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 Gaussian Blur Defense\n",
    "print(f\"\\n Testing VGG19 with Gaussian Blur Defense...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load the VGG19 model for defense testing\n",
    "if os.path.exists('best_vgg19_skin_cancer_model.pth'):\n",
    "    # Recreate VGG19 model structure\n",
    "    vgg_base_model = models.vgg19(weights='IMAGENET1K_V1')\n",
    "    vgg19_defense_model = VGG19SkinCancer(vgg_base_model, num_classes=2)\n",
    "    vgg19_defense_model.load_state_dict(torch.load('best_vgg19_skin_cancer_model.pth', map_location=device))\n",
    "    vgg19_defense_model = vgg19_defense_model.to(device)\n",
    "    print(\" VGG19 model loaded for defense testing\")\n",
    "else:\n",
    "    print(\" VGG19 model not found\")\n",
    "    vgg19_defense_model = None\n",
    "\n",
    "# Define Gaussian blur transform for defense\n",
    "from torchvision.transforms import GaussianBlur\n",
    "blur_transform = GaussianBlur(kernel_size=5, sigma=1.8)\n",
    "\n",
    "if vgg19_defense_model is not None:\n",
    "    # Test VGG19 on clean images (before attack)\n",
    "    vgg19_defense_model.eval()\n",
    "    correct_clean = 0\n",
    "    total_clean = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"VGG19 Clean Images\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = vgg19_defense_model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_clean += labels.size(0)\n",
    "            correct_clean += (predicted == labels).sum().item()\n",
    "    \n",
    "    vgg19_clean_acc = correct_clean / total_clean\n",
    "    \n",
    "    # Test VGG19 on adversarial images (after FGSM attack)\n",
    "    correct_attacked = 0\n",
    "    total_attacked = 0\n",
    "    epsilon = 3.815  # Use same epsilon as previous attack\n",
    "    \n",
    "    # FGSM Attack - REMOVE torch.no_grad() for gradient computation\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"VGG19 FGSM Attack\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = vgg19_defense_model(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        \n",
    "        # Backward pass to get gradients\n",
    "        vgg19_defense_model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Create adversarial examples using FGSM\n",
    "        data_grad = inputs.grad.data\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        adversarial_inputs = inputs + epsilon * sign_data_grad\n",
    "        adversarial_inputs = torch.clamp(adversarial_inputs, 0, 1)\n",
    "        \n",
    "        # Test on adversarial examples (no gradients needed for evaluation)\n",
    "        with torch.no_grad():\n",
    "            adv_outputs = vgg19_defense_model(adversarial_inputs)\n",
    "            _, adv_predicted = torch.max(adv_outputs.data, 1)\n",
    "            total_attacked += labels.size(0)\n",
    "            correct_attacked += (adv_predicted == labels).sum().item()\n",
    "    \n",
    "    vgg19_attacked_acc = correct_attacked / total_attacked\n",
    "    \n",
    "    # Test VGG19 with Gaussian blur defense on adversarial images\n",
    "    correct_defended = 0\n",
    "    total_defended = 0\n",
    "    \n",
    "    # FGSM Attack + Blur Defense - REMOVE torch.no_grad() for gradient computation\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"VGG19 Blur Defense\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = vgg19_defense_model(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        \n",
    "        # Backward pass to get gradients\n",
    "        vgg19_defense_model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Create adversarial examples using FGSM\n",
    "        data_grad = inputs.grad.data\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        adversarial_inputs = inputs + epsilon * sign_data_grad\n",
    "        adversarial_inputs = torch.clamp(adversarial_inputs, 0, 1)\n",
    "        \n",
    "        # Apply Gaussian blur defense\n",
    "        blurred_adversarial = blur_transform(adversarial_inputs)\n",
    "        \n",
    "        # Test on blurred adversarial examples (no gradients needed for evaluation)\n",
    "        with torch.no_grad():\n",
    "            blur_outputs = vgg19_defense_model(blurred_adversarial)\n",
    "            _, blur_predicted = torch.max(blur_outputs.data, 1)\n",
    "            total_defended += labels.size(0)\n",
    "            correct_defended += (blur_predicted == labels).sum().item()\n",
    "    \n",
    "    vgg19_defended_acc = correct_defended / total_defended\n",
    "    \n",
    "    # Display VGG19 results\n",
    "    print(f\"\\n VGG19 Model Defense Results:\")\n",
    "    print(f\"   🔸 Clean Images Accuracy:     {vgg19_clean_acc:.4f} ({vgg19_clean_acc*100:.2f}%)\")\n",
    "    print(f\"   🔸 After FGSM Attack:         {vgg19_attacked_acc:.4f} ({vgg19_attacked_acc*100:.2f}%)\")\n",
    "    print(f\"   🔸 With Gaussian Blur:        {vgg19_defended_acc:.4f} ({vgg19_defended_acc*100:.2f}%)\")\n",
    "    print(f\"   🔸 Defense Improvement:       +{(vgg19_defended_acc - vgg19_attacked_acc)*100:.2f}%\")\n",
    "    print(f\"   🔸 Recovery Rate:             {(vgg19_defended_acc / vgg19_clean_acc)*100:.1f}%\")\n",
    "else:\n",
    "    print(\" Cannot test VGG19 defense - model not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision Transformer(Vit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c87be",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from google.colab import drive\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7767406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ce5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224  # 224x224 as mentioned in paper\n",
    "NUM_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e475bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'E://data'\n",
    "train_path = os.path.join(dataset_path, 'train')\n",
    "test_path = os.path.join(dataset_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_path = os.path.join(train_path, 'benign')\n",
    "train_malignant_path = os.path.join(train_path, 'malignant')\n",
    "test_benign_path = os.path.join(test_path, 'benign')\n",
    "test_malignant_path = os.path.join(test_path, 'malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1602cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking dataset structure...\")\n",
    "print(f\"Dataset folder exists: {os.path.exists(dataset_path)}\")\n",
    "print(f\"Train folder exists: {os.path.exists(train_path)}\")\n",
    "print(f\"Test folder exists: {os.path.exists(test_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrain folders:\")\n",
    "print(f\"  Train/Benign exists: {os.path.exists(train_benign_path)}\")\n",
    "print(f\"  Train/Malignant exists: {os.path.exists(train_malignant_path)}\")\n",
    "\n",
    "print(\"\\nTest folders:\")\n",
    "print(f\"  Test/Benign exists: {os.path.exists(test_benign_path)}\")\n",
    "print(f\"  Test/Malignant exists: {os.path.exists(test_malignant_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce500eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_count = len([f for f in os.listdir(train_benign_path) if f.endswith('.jpg')])\n",
    "print(f\"  Train/Benign images: {train_benign_count}\")\n",
    "\n",
    "train_malignant_count = len([f for f in os.listdir(train_malignant_path) if f.endswith('.jpg')])\n",
    "print(f\"  Train/Malignant images: {train_malignant_count}\")\n",
    "\n",
    "test_benign_count = len([f for f in os.listdir(test_benign_path) if f.endswith('.jpg')])\n",
    "print(f\"  Test/Benign images: {test_benign_count}\")\n",
    "\n",
    "test_malignant_count = len([f for f in os.listdir(test_malignant_path) if f.endswith('.jpg')])\n",
    "print(f\"  Test/Malignant images: {test_malignant_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1092c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, label, max_samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Get all jpg files\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "\n",
    "    # Randomly select max_samples files\n",
    "    if len(files) > max_samples:\n",
    "        files = random.sample(files, max_samples)\n",
    "\n",
    "    print(f\"Loading {len(files)} images from {folder_path.split('/')[-1]} folder...\")\n",
    "\n",
    "    for i, filename in enumerate(files):\n",
    "        try:\n",
    "            # Load and resize image (ViT uses 224x224)\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = load_img(img_path, target_size=(224, 224))  # ViT standard size\n",
    "            img_array = img_to_array(img)\n",
    "\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"  Processed {i + 1}/{len(files)} images\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf42749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_images, train_benign_labels = load_images(train_benign_path, 0, NUM_SAMPLES)  # 0 for benign\n",
    "train_malignant_images, train_malignant_labels = load_images(train_malignant_path, 1, NUM_SAMPLES)  # 1 for malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training data\n",
    "X_train = np.concatenate([train_benign_images, train_malignant_images], axis=0)\n",
    "y_train = np.concatenate([train_benign_labels, train_malignant_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_benign_images, test_benign_labels = load_images(test_benign_path, 0, NUM_SAMPLES)  # 0 for benign\n",
    "test_malignant_images, test_malignant_labels = load_images(test_malignant_path, 1, NUM_SAMPLES)  # 1 for malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41908e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test data\n",
    "X_test = np.concatenate([test_benign_images, test_malignant_images], axis=0)\n",
    "y_test = np.concatenate([test_benign_labels, test_malignant_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Dataset Summary ===\")\n",
    "print(f\"Training set:\")\n",
    "print(f\"  Total images: {len(X_train)}\")\n",
    "print(f\"  Benign images: {np.sum(y_train == 0)}\")\n",
    "print(f\"  Malignant images: {np.sum(y_train == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ad8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Total images: {len(X_test)}\")\n",
    "print(f\"  Benign images: {np.sum(y_test == 0)}\")\n",
    "print(f\"  Malignant images: {np.sum(y_test == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nImage specifications:\")\n",
    "print(f\"  Image shape: {X_train[0].shape}\")\n",
    "print(f\"  Pixel value range: [{X_train.min():.3f}, {X_train.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ede74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Display sample images\n",
    "def display_sample_images(X, y, title=\"Sample Images\", num_samples=6):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        idx = random.randint(0, len(X) - 1)\n",
    "        img = X[idx]\n",
    "        label = 'Malignant' if y[idx] == 1 else 'Benign'\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'{label}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bdfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from training set\n",
    "print(\"\\n=== Displaying Sample Training Images ===\")\n",
    "display_sample_images(X_train, y_train, \"Training Set - Sample Images\")\n",
    "\n",
    "print(\"\\nDataset loading completed successfully!\")\n",
    "print(\"\\nVariables created:\")\n",
    "print(\"- X_train: Training images\")\n",
    "print(\"- X_test: Test images\")\n",
    "print(\"- y_train: Training labels (0=benign, 1=malignant)\")\n",
    "print(\"- y_test: Test labels (0=benign, 1=malignant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94ad2b",
   "metadata": {},
   "source": [
    "## Dataset Prep ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daabd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting labels to one-hot encoding...\")\n",
    "\n",
    "# Label encoding (assuming you have y_train and y_test from your data loading)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert to one-hot encoding (categorical)\n",
    "y_train_onehot = to_categorical(y_train_encoded, num_classes=2)\n",
    "y_test_onehot = to_categorical(y_test_encoded, num_classes=2)\n",
    "\n",
    "print(f\"Original labels shape: {y_train.shape}\")\n",
    "print(f\"One-hot encoded labels shape: {y_train_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples\n",
    "print(f\"Example - Original: {y_train[:5]} -> One-hot: {y_train_onehot[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train_onehot,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y_train_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87522d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final training set: {len(X_train_final)} images\")\n",
    "print(f\"Validation set: {len(X_val)} images\")\n",
    "print(f\"Test set: {len(X_test)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66747064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(f\"\\nClass distribution in final training set:\")\n",
    "print(f\"  Benign: {np.sum(np.argmax(y_train_final, axis=1) == 0)}\")\n",
    "print(f\"  Malignant: {np.sum(np.argmax(y_train_final, axis=1) == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nClass distribution in validation set:\")\n",
    "print(f\"  Benign: {np.sum(np.argmax(y_val, axis=1) == 0)}\")\n",
    "print(f\"  Malignant: {np.sum(np.argmax(y_val, axis=1) == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT preprocessing function\n",
    "def preprocess_input(x):\n",
    "    \"\"\"\n",
    "    Hugging Face ViT preprocessing\n",
    "    Normalize to [0, 1] and then to ImageNet stats\n",
    "    \"\"\"\n",
    "    # First normalize to [0, 1]\n",
    "    x = x / 255.0\n",
    "    # Then apply ImageNet normalization\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    x = (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda75558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators with ViT preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # Use ViT's built-in preprocessing\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f08804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation and test data generators (no augmentation, only rescaling)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input  # Use ViT's built-in preprocessing\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input  # Use ViT's built-in preprocessing\n",
    ")\n",
    "\n",
    "print(\"Data augmentation parameters:\")\n",
    "print(f\"  - Rotation range: 15°\")\n",
    "print(f\"  - Width/Height shift: 10%\")\n",
    "print(f\"  - Horizontal flip: Yes\")\n",
    "print(f\"  - Zoom range: 10%\")\n",
    "print(f\"  - Shear range: 10%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ca8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    X_val, y_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "    X_test, y_test_onehot,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"   Data generators created with batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Training batches per epoch: {len(train_generator)}\")\n",
    "print(f\"   Validation batches per epoch: {len(val_generator)}\")\n",
    "print(f\"   Test batches: {len(test_generator)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize augmented images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_augmented_images(generator, num_images=6):\n",
    "    \"\"\"Display original and augmented images\"\"\"\n",
    "    # Get a batch from the generator\n",
    "    batch_images, batch_labels = next(generator)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(min(num_images, len(batch_images))):\n",
    "        img = batch_images[i]\n",
    "        label = np.argmax(batch_labels[i])\n",
    "        label_name = 'Malignant' if label == 1 else 'Benign'\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Augmented {label_name}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle('Sample Augmented Training Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"   Displaying sample augmented images...\")\n",
    "show_augmented_images(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa7c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
