{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8f6519",
   "metadata": {},
   "source": [
    "VGG-19 IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37abda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from google.colab import drive\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48822874",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224  # 224x224 as mentioned in paper\n",
    "NUM_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd077b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'E://data'\n",
    "train_path = os.path.join(dataset_path, 'train')\n",
    "test_path = os.path.join(dataset_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_path = os.path.join(train_path, 'benign')\n",
    "train_malignant_path = os.path.join(train_path, 'malignant')\n",
    "test_benign_path = os.path.join(test_path, 'benign')\n",
    "test_malignant_path = os.path.join(test_path, 'malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking dataset structure...\")\n",
    "print(f\"Dataset folder exists: {os.path.exists(dataset_path)}\")\n",
    "print(f\"Train folder exists: {os.path.exists(train_path)}\")\n",
    "print(f\"Test folder exists: {os.path.exists(test_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c327703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrain folders:\")\n",
    "print(f\"  Train/Benign exists: {os.path.exists(train_benign_path)}\")\n",
    "print(f\"  Train/Malignant exists: {os.path.exists(train_malignant_path)}\")\n",
    "\n",
    "print(\"\\nTest folders:\")\n",
    "print(f\"  Test/Benign exists: {os.path.exists(test_benign_path)}\")\n",
    "print(f\"  Test/Malignant exists: {os.path.exists(test_malignant_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da967",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_count = len([f for f in os.listdir(train_benign_path) if f.endswith('.jpg')])\n",
    "print(f\"  Train/Benign images: {train_benign_count}\")\n",
    "\n",
    "train_malignant_count = len([f for f in os.listdir(train_malignant_path) if f.endswith('.jpg')])\n",
    "print(f\"  Train/Malignant images: {train_malignant_count}\")\n",
    "\n",
    "test_benign_count = len([f for f in os.listdir(test_benign_path) if f.endswith('.jpg')])\n",
    "print(f\"  Test/Benign images: {test_benign_count}\")\n",
    "\n",
    "test_malignant_count = len([f for f in os.listdir(test_malignant_path) if f.endswith('.jpg')])\n",
    "print(f\"  Test/Malignant images: {test_malignant_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf1e48",
   "metadata": {},
   "source": [
    "Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, label, max_samples=500):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Get all jpg files\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "\n",
    "    # Randomly select max_samples files\n",
    "    if len(files) > max_samples:\n",
    "        files = random.sample(files, max_samples)\n",
    "\n",
    "    print(f\"Loading {len(files)} images from {folder_path.split('/')[-1]} folder...\")\n",
    "\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),  # Converts PIL image to tensor and normalizes to [0,1]\n",
    "    ])\n",
    "\n",
    "    for i, filename in enumerate(files):\n",
    "        try:\n",
    "            # Load and transform image\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = transform(img)\n",
    "\n",
    "            # Convert to numpy for consistency with rest of code\n",
    "            img_array = img_tensor.permute(1, 2, 0).numpy()  # CHW -> HWC\n",
    "\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"  Processed {i + 1}/{len(files)} images\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_benign_images, train_benign_labels = load_images(train_benign_path, 0, NUM_SAMPLES)  # 0 for benign\n",
    "train_malignant_images, train_malignant_labels = load_images(train_malignant_path, 1, NUM_SAMPLES)  # 1 for malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training data\n",
    "X_train = np.concatenate([train_benign_images, train_malignant_images], axis=0)\n",
    "y_train = np.concatenate([train_benign_labels, train_malignant_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a45d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_benign_images, test_benign_labels = load_images(test_benign_path, 0, NUM_SAMPLES)  # 0 for benign\n",
    "test_malignant_images, test_malignant_labels = load_images(test_malignant_path, 1, NUM_SAMPLES)  # 1 for malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test data\n",
    "X_test = np.concatenate([test_benign_images, test_malignant_images], axis=0)\n",
    "y_test = np.concatenate([test_benign_labels, test_malignant_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36159c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Dataset Summary ===\")\n",
    "print(f\"Training set:\")\n",
    "print(f\"  Total images: {len(X_train)}\")\n",
    "print(f\"  Benign images: {np.sum(y_train == 0)}\")\n",
    "print(f\"  Malignant images: {np.sum(y_train == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61650184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Total images: {len(X_test)}\")\n",
    "print(f\"  Benign images: {np.sum(y_test == 0)}\")\n",
    "print(f\"  Malignant images: {np.sum(y_test == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d55429",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nImage specifications:\")\n",
    "print(f\"  Image shape: {X_train[0].shape}\")\n",
    "print(f\"  Pixel value range: [{X_train.min():.3f}, {X_train.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d300859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Display sample images\n",
    "def display_sample_images(X, y, title=\"Sample Images\", num_samples=6):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        idx = random.randint(0, len(X) - 1)\n",
    "        img = X[idx]\n",
    "        label = 'Malignant' if y[idx] == 1 else 'Benign'\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'{label}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10123872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from training set\n",
    "print(\"\\n=== Displaying Sample Training Images ===\")\n",
    "display_sample_images(X_train, y_train, \"Training Set - Sample Images\")\n",
    "\n",
    "print(\"\\nDataset loading completed successfully!\")\n",
    "print(\"\\nVariables created:\")\n",
    "print(\"- X_train: Training images\")\n",
    "print(\"- X_test: Test images\")\n",
    "print(\"- y_train: Training labels (0=benign, 1=malignant)\")\n",
    "print(\"- y_test: Test labels (0=benign, 1=malignant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66d1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c579856",
   "metadata": {},
   "source": [
    "Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c32686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8bc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: One-hot Encoding\n",
    "print(\"1. Converting labels to one-hot encoding...\")\n",
    "\n",
    "# Create label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform training labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert to one-hot encoding using PyTorch\n",
    "y_train_onehot = F.one_hot(torch.tensor(y_train_encoded), num_classes=2).float().numpy()\n",
    "y_test_onehot = F.one_hot(torch.tensor(y_test_encoded), num_classes=2).float().numpy()\n",
    "\n",
    "print(f\"Original labels shape: {y_train.shape}\")\n",
    "print(f\"One-hot encoded labels shape: {y_train_onehot.shape}\")\n",
    "print(f\"Label mapping: {dict(enumerate(label_encoder.classes_))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show examples\n",
    "print(f\"Example - Original: {y_train[:5]} -> One-hot: {y_train_onehot[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train_onehot,\n",
    "    test_size=0.3,           # 30% for validation\n",
    "    random_state=42,\n",
    "    stratify=y_train_encoded  # Stratified sampling to maintain class balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final training set: {len(X_train_final)} images\")\n",
    "print(f\"Validation set: {len(X_val)} images\")\n",
    "print(f\"Test set: {len(X_test)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(f\"\\nClass distribution in final training set:\")\n",
    "print(f\"  Benign: {np.sum(np.argmax(y_train_final, axis=1) == 0)}\")\n",
    "print(f\"  Malignant: {np.sum(np.argmax(y_train_final, axis=1) == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nClass distribution in validation set:\")\n",
    "print(f\"  Benign: {np.sum(np.argmax(y_val, axis=1) == 0)}\")\n",
    "print(f\"  Malignant: {np.sum(np.argmax(y_val, axis=1) == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ac5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation using PyTorch transforms\n",
    "print(\"   Setting up data augmentation...\")\n",
    "print(\"   Rotation range: 15 degrees (as mentioned in paper)\")\n",
    "\n",
    "# ImageNet normalization values for VGG19\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Create data augmentation transforms for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(15),          # Rotate images by up to 15 degrees\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # Flip images horizontally\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Color jittering\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=0.1),  # Translation and shear\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),  # VGG19 ImageNet normalization\n",
    "])\n",
    "\n",
    "# Validation and test transforms (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),  # VGG19 ImageNet normalization\n",
    "])\n",
    "\n",
    "print(\"Data augmentation parameters:\")\n",
    "print(f\"  - Rotation range: 15°\")\n",
    "print(f\"  - Horizontal flip: 50% probability\")\n",
    "print(f\"  - Color jitter: brightness/contrast ±10%\")\n",
    "print(f\"  - Translation: ±10%\")\n",
    "print(f\"  - Shear range: 10%\")\n",
    "print(f\"  - ImageNet normalization: mean={IMAGENET_MEAN}, std={IMAGENET_STD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation and test data generators (no augmentation, only rescaling)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "val_datagen = ImageDataGenerator(rescale=1.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0)\n",
    "\n",
    "print(\"Data augmentation parameters:\")\n",
    "print(f\"  - Rotation range: 15°\")\n",
    "print(f\"  - Width/Height shift: 10%\")\n",
    "print(f\"  - Horizontal flip: Yes\")\n",
    "print(f\"  - Zoom range: 10%\")\n",
    "print(f\"  - Shear range: 10%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets and dataloaders\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SkinCancerDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert numpy array to uint8 for PIL transforms\n",
    "        if image.max() <= 1.0:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image).permute(2, 0, 1).float() / 255.0  # HWC -> CHW and normalize\n",
    "\n",
    "        # Convert one-hot label to class index for PyTorch\n",
    "        if len(label.shape) > 0 and label.shape[0] > 1:  # one-hot encoded\n",
    "            label = torch.tensor(np.argmax(label)).long()\n",
    "        else:\n",
    "            label = torch.tensor(label).long()\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SkinCancerDataset(X_train_final, y_train_final, transform=train_transform)\n",
    "val_dataset = SkinCancerDataset(X_val, y_val, transform=val_test_transform)\n",
    "test_dataset = SkinCancerDataset(X_test, y_test_onehot, transform=val_test_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"   Data loaders created with batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Training batches per epoch: {len(train_loader)}\")\n",
    "print(f\"   Validation batches per epoch: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcc344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize augmented images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_augmented_images(dataloader, num_images=6):\n",
    "    \"\"\"Display original and augmented images\"\"\"\n",
    "    # Get a batch from the dataloader\n",
    "    dataiter = iter(dataloader)\n",
    "    batch_images, batch_labels = next(dataiter)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(min(num_images, len(batch_images))):\n",
    "        # Convert tensor to numpy for display (CHW -> HWC)\n",
    "        img = batch_images[i].permute(1, 2, 0).numpy()\n",
    "        # Ensure values are in [0,1] range for display\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        label = batch_labels[i].item()\n",
    "        label_name = 'Malignant' if label == 1 else 'Benign'\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Augmented {label_name}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle('Sample Augmented Training Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"   Displaying sample augmented images...\")\n",
    "show_augmented_images(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b61d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset the dataloader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Summary\n",
    "print(\"\\n=== Dataset Preparation Summary ===\")\n",
    "print(\"✓ Labels converted to one-hot encoding\")\n",
    "print(\"✓ Data split using stratified sampling (70% train, 30% validation)\")\n",
    "print(\"✓ Data augmentation applied to training set\")\n",
    "print(\"✓ Data generators created for training, validation, and testing\")\n",
    "print(\"\\nDataset is ready for VGG-19 model training!\")\n",
    "\n",
    "print(\"\\nVariables available for next step:\")\n",
    "print(\"- train_generator: Training data with augmentation\")\n",
    "print(\"- val_generator: Validation data\")\n",
    "print(\"- test_generator: Test data\")\n",
    "print(\"- X_train_final, y_train_final: Final training arrays\")\n",
    "print(\"- X_val, y_val: Validation arrays\")\n",
    "print(\"- X_test, y_test_onehot: Test arrays with one-hot labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af3789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc0f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
